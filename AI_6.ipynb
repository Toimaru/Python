{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各種ライブラリが必要となるため、プログラム実行時はインストールすること\n",
    "\n",
    "py -m pip install <ライブラリ>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前準備\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# 可視化ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "# 少数第3位まで表示\n",
    "%precision 3\n",
    "\n",
    "# グラフの日本語表記対応\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第６章 ディープラーニングの基本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1 畳み込みニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1-1 畳み込みニューラルネットワークの基本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込みニューラルネットワーク(CNN)は、順伝播型ネットワークの一種で、畳み込み層とプーリング層で構成される。主に画像認識に応用される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-1-1-1 畳み込み層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み層では、以下の流れで実施する。\n",
    "\n",
    "1. 入力画像のフチを固定値で埋める**バティング**を実施<br>入力画像と同じサイズの出力結果(特徴マップ)を得る\n",
    "1. 一定の画素分だけずらし(スライド)ながら畳み込みを計算する\n",
    "1. 得られた畳み込みの値に活性化関数を適用する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み層における重みは、全ユニットで同じである。これを重み共有という。その結果、畳み込み層のパラメータ数は全結合層のパラメータを比べて減少して計算量が少なくなる特徴がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-1-1-2 プーリング層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み層の後に配置される層である。プーリングは、最大値や平均値を用いて入力データをダウンサンプリングする。畳み込み層で抽出した特徴の位置感度を下げることにより、画像内での位置が変化した場合でもプーリング層における出力が変わらないようにしている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力画像に対して、以下のような前処理を実施することが多い。\n",
    "\n",
    "|前処理|説明|\n",
    "|---|---|\n",
    "|グレースケール化|カラー画像をモノクロ画像に変換する。<br>⇒計算量を削減可能|\n",
    "|平滑化|細かなノイズを除去|\n",
    "|ヒストグラム平均|画像全体の明暗を平均化させて、コントラストが高い画像を得る方法|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1-2 代表的なモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|モデル|説明|\n",
    "|---|---|\n",
    "|LeNet|多層のCNNに初めて誤差逆伝播法を用いた|\n",
    "|AlexNet|2012年にILSVRCで優勝|\n",
    "|GoogLeNet|2014年にインセプションモジュールというブロック構成で優勝<br>インセプションモジュールは複数の畳み込み層を並列に適用し、それぞれの畳み込み計算の結果を最後に連結|\n",
    "|VGG16|オックスフォード大学で開発した畳み込み13層、全結合層3層で計16層あるネットワーク構成|\n",
    "|ResNet|2015年にMicrosoftが開発<br>スキップコネクションを用いた残差を学習することで1000層以上の深いニューラルネットワークを構成|\n",
    "|カプセルネットワーク|ジェフリー・ヒントンらにより、2017年に提案<br>従来の手法が1つの数値を出力するのに対し、空間情報をベクトルとして出力する|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1-3 学習済みモデルの利用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既存の学習済みニューラルネットワークモデルを活用する手法には以下がある。\n",
    "\n",
    "|手法|説明|特徴|\n",
    "|---|---|---|\n",
    "|転移学習|既存の学習モデルを新しい課題のデータに利用する手法|既存の学習モデルの重みを変更しないため、<br>小規模なデータと少ない計算量で学習モデルを作成可能|\n",
    "|蒸留|大規模なニューラルネットワークのモデルの入出力を小規模なモデルに学習させる手法|少ない計算量で学習することができるようになり、<br>過学習が起こりにくくなる|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2 再帰型ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNは、内部に再帰構造を持つニューラルネットワークである。この構造により情報を一時的に記憶できるようになったため、理論的には過去のすべての入力データを扱えるようになった。この結果、音声認識や自然言語処理に利用される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNの例として、以下がある。文脈ユニットを構成しているのが特徴である。\n",
    "\n",
    "*   ジョーダンネット（入力層は、入力信号を処理する入力ユニットと直前の出力層の状態を入力とする文脈ユニットで構成）\n",
    "*   エルマンネット（入力層は入力信号を処理する入力ユニットと直前の中間層の状態を入力とする文脈ユニットで構成）\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNの問題点として、勾配消失問題が起こりやすい。\n",
    "\n",
    "これを解消するため、RNNの中間層のユニットをメモリとメモリ・セル、入力ゲート、忘却ゲートの3つのゲートを持つLSTM blockに置き換えることで、系列データにおいても勾配を消失せずに学習できる**LSTM**を実現した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNにおける学習は、時間を過去に遡って反映する**BPTT(Backpropagation Througth Time)法**が利用される。また、LSTMを簡略化した手法として、**GRU**がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般的なRNNでは、過去から未来の情報のみを使って学習するが、**双方向RNN(Bidirectional RNN)**は未来から過去への情報も同時に学習することによって、精度が向上する。ただし、双方向RNNは、未来の情報がわかっていなければ利用することができない。そのため、文章の推敲や機械翻訳、フレーム間の補完などに利用する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディープラーニングを利用することで、機械翻訳、音声認識やキャプション生成の制度が大きく向上した。それは、エンコーダーとデコーダにRNNをもいいた**RNN Encoder-Decoder**が採用された理由の1つである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3 自己符号化器(Autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自己符号化器(Autoencoder)は、出力が入力に近づくようにニューラルネットワークを学習する方法である。データの特徴獲得や次元圧縮ができる。\n",
    "\n",
    "1. 入力層：符号化を実施\n",
    "1. 中間層：入力層・出力層より少ないユニットで構成（次元を削減した入力データの特徴を抽出）\n",
    "1. 出力層：復号化を実施\n",
    "\n",
    "活性関数に恒等写像を用いた3層の自己符号化器の結果は、主成分分析で得られる結果と実質同じである。多層を扱うことで、主成分分析ではできない非線形な特徴抽出や次元圧縮が可能である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■積層自己符号化器（積層オートエンコーダ）\n",
    "\n",
    "入力層側から順に分割された単層ネットワークを自己復号化器として学習を行う。このように、自己復号化器として学習した単層ネットワークを積み重ねたもの。\n",
    "\n",
    "\n",
    "■ファインチューニング\n",
    "\n",
    "積層復号化器を積み重ねるだけでは出力することができない。そこで、出力にシグモイド関数またはソフトマックス関数を足すことでネットワークを完成させる。そして、この時に追加した出力層の重みを学習するために、ネットワーク全体で学習を行う。このように、既存の学習済みモデルを再学習する方法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-4 深層強化学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-4-1 強化学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "強化学習では、試行錯誤を通じて得られる報酬の総和である価値を最大化する行動を学習する。行動に対して報酬を得るという点について教師あり学習と似ているが、報酬の総和である価値を最大化する点が異なっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "強化学習の代表的な手法の1つに**Q学習**がある。Q学習は、その行動をとったら得られる報酬を推定することにより、可能な行動の中から最も状態行動価値の値Qが高い行動を選択することができる。状態行動価値とは、ある状態においてある行動をとった時の価値のことである。\n",
    "\n",
    "最終的に最大報酬を得るためには、一時的に報酬が下がることを許容する必要がある。最大報酬が得られる行動以外を取って探索する必要があるが、この行動をしすぎると、報酬が増えない状況が続く。このことを**探索と搾取のジレンマ**という。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "強化学習の用語を整理する。\n",
    "\n",
    "|用語|説明|\n",
    "|---|---|\n",
    "|エージェント|ある環境で動くプレイヤー|\n",
    "|状態|エージェントが置かれている環境|\n",
    "|行動|エージェントがとる行動|\n",
    "|収益|エージェントが行動することにより得られる評価値|\n",
    "|価値関数|将来的に得られる収益の期待値を表す関数|\n",
    "|方策|ある状態のとき、どの行動をとるべきかを示す関数<br>決定的に行動を決めるものと確率的に決めるものがある|\n",
    "|Deep Q-Network (DQN)|次の章を参照|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-4-2 深層強化学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepMindが開発した**DQN**は、強化学習において行動価値関数の関数近似に畳み込みニューラルネットワークを用いた手法である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-5 その他の手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-5-1 ボルツマンマシン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ボルツマンマシンは、ジェフリー・ヒントンらによって1985年に提案された確率的に動作するニューラルネットワークのことである。ネットワークの動作に温度の概念を取り入れている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-5-2 深層生成モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成モデルとは訓練データを学習し、どれらのデータと似たような新しいデータを生成することができるモデルである。\n",
    "\n",
    "ディープラーニングを利用した生成モデルである深層生成モデルには、以下がある。\n",
    "\n",
    "1. GAN(Generative Adversarial Network:敵対的生成ネットワーク)\n",
    "1. VAE(Variational Autoencoderl:変分自己符号化器)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
