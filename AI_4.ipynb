{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各種ライブラリが必要となるため、プログラム実行時はインストールすること\n",
    "\n",
    "py -m pip install <ライブラリ>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前準備\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# 可視化ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "# 少数第3位まで表示\n",
    "%precision 3\n",
    "\n",
    "# グラフの日本語表記対応\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第４章 機械学習の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習の実装フローは以下である。\n",
    "\n",
    "1. 事前準備\n",
    "1. 前処理\n",
    "1. モデルの学習\n",
    "1. モデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1-1 データの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データはどんなものでもよいわけではなく、サービスに応じたデータであり、同じようなデータではなく多種多様なデータを用意するほうが好ましい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1-2 手法の選択"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習の手法を選定する。ディープラーニングを利用するのであれば、利用するモデルも検討する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2-1 データの選別・データクレンジング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの選別：\n",
    "\n",
    "　収集したデータから使えないデータを除き、使用するデータを選別する\n",
    "\n",
    "データクレンジング：\n",
    "\n",
    "　データ選別したデータを整える\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2-2 特性スケーリング(Feature Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特性スケーリングは、特徴量の取り得る値の範囲(スケール)を変えることである。例えば、試験の点数を学習するとき、平均点が高い科目と低い科目に対して、点数を調整する処理が該当する。\n",
    "\n",
    "この特性スケーリングを行うことで、学習の収束までの時間が短くなることや、モデルの性能向上が期待できる。主な特徴スケーリングは以下である。\n",
    "\n",
    "|スケーリング方法|説明|\n",
    "|---|---|\n",
    "|正規化|データの値が0～1などの指定範囲に収まるように、値を加工するテクニック<br>例えば、画像処理における色の濃さを調整する処理がある|\n",
    "|標準化|データの平均が0、分散が1になるように、値を加工するテクニック|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2-3 アノテーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アノテーションは、収集したデータに意味付け(タグ付け)を与えるプロセスである。例えば、犬の画像に対して種別情報を付与する、口コミに対してよい評価/悪い評価のラベルを付与する、人の顔画像に対して、目・鼻・口の位置をポイントする、などがある。\n",
    "\n",
    "データに対して、正しいタグ付けをすることにより、データから正確に情報を読み取ることができるようになる。これがモデルの学習精度の向上に直結する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2-4 データの拡張"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データを増やすために、データの拡張をすることがある。例えば、収集した犬の画像データは、拡大しても左右反転してもいぬであるので、収集したデータを加工することで学習データを数倍に増やすことができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3 モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3-1 ハイパーパラメータのチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-3-1-1 ハイパーパラメータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習において、学習時に更新するパラメータとは別に、学習前に予め決めておく値を**ハイパーパラメータ**という。このハイパーパラメータは、絶対的な正解があるわけではない。感覚や経験による調整が必要になる。\n",
    "\n",
    "|項目|説明|\n",
    "|---|---|\n",
    "|パラメータ|重み、バイアスなど学習によって更新されるパラメータ|\n",
    "|ハイパーパラメータ|学習における初期値やモデルのニューロンの数など、学習に影響する学習前に予めきめておく値|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-3-1-2 学習率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習率は、1度の学習で「どのくらい重みを更新するか」というパラメータを指す。\n",
    "\n",
    "||メリット|デメリット|\n",
    "|---|---|---|\n",
    "|学習率を大きくする|学習が早い<br>収束するまでの時間が短い|発散する傾向が強くなる|\n",
    "|学習率を小さくする|収束時の誤差は小さくなる|学習までにかかる時間が長くなる|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-3-1-3 パラメータの更新単位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|学習単位|説明|例(1000件の場合)|\n",
    "|---|---|---|\n",
    "|バッチサイズ|訓練データをいくつかのデータセットに分割し、分割したデータセットに含まれるデータの数|200件|\n",
    "|イテレーション数|訓練データに含まれるデータが少なくとも1回は学習に用いられるのに必要な学習回数|1000/200件=5回|\n",
    "|エポック数|すべての訓練データを学習すると1エポック|イテレーションを全部実施(1エポック)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3-2 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データとして入力データと正解が与えられたとき、正解と機械学習の予測結果とがなるべく近づくように重みを更新する。これを学習という。正解と予測の差を小さくするようにハイパーパラメータをチューニングする。\n",
    "\n",
    "|項目|説明|\n",
    "|---|---|\n",
    "|汎化誤差|未知のデータに対する予測と実際の差<br>バイアス、バリアンス、ノイズの3要素がある|\n",
    "|誤差関数|正解ラベルと予測の近さを評価|\n",
    "\n",
    "<br>\n",
    "\n",
    "|汎化誤差の要素|説明|\n",
    "|---|---|\n",
    "|バイアス|予測モデルと学習データとの差の平均を数値化したもの<br>予測モデルが単純すぎる場合に大きくなる(汎化できていないモデルと判断)|\n",
    "|バリアンス|予測モデルの複雑さを数値化したもの<br>バイアスとは逆で予測モデルが複雑すぎる場合に大きくなる(汎化できないモデルと判断)|\n",
    "|ノイズ|削除不能な誤差<br>学習データ自体に余計なデータが混ざっている場合に大きくなる|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測モデルが単純すぎるとバイアスが増え、複雑すぎるとバリアンスが増えるため、両者はトレードオフの関係があり、バランスの取れたモデルを考える必要がある。このバランスの良さを測る指標が汎化誤差である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-4 モデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4-1 評価方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-4-1-1 交差検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習においてデータを学習した後は、学習したモデルの性能を評価する必要がある。モデルの評価は、未知のデータに対する予測精度を測ることになるため、学習データとは別のデータを用いるのが望ましい。データは手元のデータを訓練データ(学習に利用)とテストデータ(性能評価に利用)に分けることが一般的である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-4-1-2 ホールド・アウト(holdout method)法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データとテストデータの2つにランダムに分割し、訓練データでモデルを構築し、その後、テストデータでモデルを検証する方法である。\n",
    "\n",
    "教師あり学習では、訓練データを基地のデータとみなし、テストデータを未知のデータとみなすことで、その道のデータにおける性能を評価できる。ホールドアウト法は非常にシンプルであるが、データ数が十分大きい時には、モデルの評価方法として実用的に使える。\n",
    "\n",
    "しかし、データ数が限られるときは、以下の問題が生じる。\n",
    "\n",
    "\n",
    "\n",
    "*   ランダムに分割された特定のテストデータによっては、たまたま高く評価される可能性がある\n",
    "*   限られたデータを訓練用とテスト用に分割するため、学習データ数が削られ、肝心の学習が十分に進まない可能性がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率(訓練)：0.9765258215962441\n",
      "正解率(テスト)：0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# ホールドアウト法                              #\n",
    "# 乳がんデータを決定木モデルで実施            #\n",
    "###############################################\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データ読み込み\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# 決定木モデル初期化\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "\n",
    "# ホールドアウト法(データ分割)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data,\n",
    "    cancer.target,\n",
    "    stratify = cancer.target,\n",
    "    random_state = 0\n",
    ")\n",
    "\n",
    "# 学習\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# 検証結果の表示\n",
    "print('正解率(訓練)：{}'.format(tree.score(X_train, y_train)))\n",
    "print('正解率(テスト)：{}'.format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-4-1-3 k-分割交差検証(k-fold cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データとテストデータの分割を複数回行い、それぞれで学習と評価を行う方法である。分割する数をkで表す。すなわち、データを分割し、分割したデータでホールドアウト法を実施し、検証結果の平均をモデルの性能とする評価方法である。\n",
    "\n",
    "**k-分割交差検証**は、評価するということを繰り返すことでテスト結果が平均化されるため、テストデータにデータの偏りがある場合も影響を受けにくいという利点がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores：[0.904 0.912 0.956 0.939 0.956]\n",
      "Cross validation scores：0.933+-0.022\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# k-分割交差検証                              #\n",
    "# 乳がんデータを決定木モデルで実施            #\n",
    "###############################################\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# データ読み込み\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# 決定木モデル初期化\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "\n",
    "# k-分割交差検証\n",
    "scores = cross_val_score(tree, cancer.data, cancer.target, cv=5)\n",
    "\n",
    "# 検証結果の表示\n",
    "print('Cross validation scores：{}'.format(scores))\n",
    "print('Cross validation scores：{:.3f}+-{:.3f}'.format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4-2 評価指標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-4-2-1 評価指標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの性能を評価する際、混合行列(confusion matrix)を利用して以下のように考える。\n",
    "\n",
    "|実際の値/予測値|陽性(Positive)|陰性(Negative)|\n",
    "|---|---|---|\n",
    "|陽性(Positive)|真陽性(True Positive：TP)<br>陽性を予測したが、実際は陽性|偽陰性(False Negative：FN)<br>陰性を予測したが、実際は陽性|\n",
    "|陰性(Negative)|偽陽性(False Positive：FP)<br>陽性を予測したが、実際は陰性|真陰性(True Negative：TN)<br>陰性を予測したが、実際は陰性|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[81  9]\n",
      " [ 4 49]]\n",
      "|       |   pred_1 |   pred_0 |\n",
      "|:------|---------:|---------:|\n",
      "| act_1 |       81 |        9 |\n",
      "| act_0 |        4 |       49 |\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# 混合行列                              #\n",
    "#########################################\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# データ読み込み\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# データ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data,\n",
    "    cancer.target,\n",
    "    stratify=cancer.target,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# 初期化と学習\n",
    "model = SVC(gamma=0.001, C=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 予測\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 混合行列表示\n",
    "labels = [1, 0]\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "print('Confusion Matrix:\\n{}'.format(cm))\n",
    "\n",
    "# きれいに出力\n",
    "columns_labels = [\"pred_\" + str(l) for l in labels]\n",
    "index_labels = [\"act_\" + str(l) for l in labels]\n",
    "df = pd.DataFrame(cm,\n",
    "                  columns=columns_labels, index=index_labels)\n",
    "\n",
    "print(df.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを評価する指標として以下がある。\n",
    "\n",
    "|評価指標|説明|メリット|デメリット|\n",
    "|---|---|---|---|\n",
    "|正答率/正解率(Accuracy)|予測結果と答えがどれくらい一致しているかを測る指標<br>$$正解率 = \\frac{予測と正解が一致している数}{全体の数} = \\frac{TP+TN}{TP+TN+FP+FN}$$<br>試験の正解率を表す場合などによく用いられる。|最もシンプルで分かりやすい|クラスごとの評価データ数が著しく異なると不適切|\n",
    "|適合率(Precision)|陽性と予測した内、どれだけ実際に陽性だったかを測る指標<br>$$適合率 = \\frac{実際に陽性だった数}{陽性と予測した数} = \\frac{TP}{TP+FP}$$<br>誤診する可能性を低く抑えたい場合によく用いられる。|過検知を発見できる|取りこぼしを発見できない|\n",
    "|再現率(Recall)|実際に陽性だったうち、どれだけ陽性を予測できていたかを測る指標<br>$$再現率 = \\frac{陽性と予測できた数}{実際に陽性だった数} = \\frac{TP}{TP+FN}$$<br>確実に発病している人を検知したいなど、なるべく漏れを防ぎたい場合に用いられる。|取りこぼしを発見できる|過検知を発見できない|\n",
    "|F値(F-measure, F-score)|一般的に、適合率と再現率はトレードオフの関係にある。<br>そのため、適合率と再現率の調和平均をとった指標<br>$$F値 = \\frac{2 \\cdot 適合率 \\cdot 再現率}{(適合率+再現率)}$$|取りこぼし、過検知をどちらも均等に判断できる|数値の解釈が難しくなる|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率：0.909\n",
      "適合率：0.953\n",
      "再現率：0.900\n",
      "F値：0.926\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# 各種指標の計算                           #\n",
    "############################################\n",
    "\n",
    "accuracy = (cm[0, 0] + cm[1, 1]) / cm.sum()\n",
    "precision = (cm[0, 0]) / cm[:, 0].sum()\n",
    "recall = (cm[0, 0]) / cm[0, :].sum()\n",
    "fmesure = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print('正解率：{:.3f}'.format(accuracy))\n",
    "print('適合率：{:.3f}'.format(precision))\n",
    "print('再現率：{:.3f}'.format(recall))\n",
    "print('F値：{:.3f}'.format(fmesure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "適合率：0.953\n",
      "再現率：0.900\n",
      "F値：0.926\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# 各種指標の計算（関数利用）               #\n",
    "############################################\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print('適合率：{:.3f}'.format(precision_score(y_test, y_pred)))\n",
    "print('再現率：{:.3f}'.format(recall_score(y_test, y_pred)))\n",
    "print('F値：{:.3f}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-4-2-2 過学習(Over Fitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディープラーニングは訓練データをもとに学習するが、訓練データに適合しすぎた状態を**過学習**という。つまり、学習データにのみ最適化され、汎用化されていないモデルになっていることである。\n",
    "\n",
    "一方、過学習を防ごうとするあまりモデルの予測性能が十分上がらない状態を**未学習**(Under Fitting)という。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "過学習を防ぐための手法として以下がある。\n",
    "\n",
    "|手法|説明|\n",
    "|---|---|\n",
    "|Lasso回帰(L1正則化)|「自動的に特徴選択を行い、重要でないと判断された特徴量を自動的にモデルから消す」効果がある|\n",
    "|Ridge回帰(L2正則化)|「パラメータの大きさに応じてゼロに近づけることで、汎化された滑らかなモデルを得る」効果がある|\n",
    "\n",
    "注意として、正則化には過学習を防ぐ効果があるが、正則化しすぎてしまうと未学習を引き起こしやすい。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
